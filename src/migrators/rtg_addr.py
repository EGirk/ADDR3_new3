"""–ü–æ–≤–Ω—ñ—Å—Ç—é —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–æ–≤–∞–Ω–∏–π –º—ñ–≥—Ä–∞—Ç–æ—Ä –¥–ª—è addr.rtg_addr –∑ —ñ–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—é —Ç–∞ –ø–æ–≤–Ω–æ—é –≤–∞–ª—ñ–¥–∞—Ü—ñ—î—é"""

import json
import sys
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# –î–æ–¥–∞—î–º–æ —à–ª—è—Ö –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import psycopg2
    from psycopg2.extras import Json, RealDictCursor
    HAS_PSYCOPG2 = True
except ImportError:
    HAS_PSYCOPG2 = False

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

try:
    from src.utils.logger import migration_logger
    from src.utils.migration_data_parser import MigrationDataParser
    from src.utils.validators import UniversalAddressComparator
except ImportError:
    # Fallback –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    import logging
    migration_logger = logging.getLogger('migration')
    migration_logger.setLevel(logging.INFO)
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    migration_logger.addHandler(handler)
    
    # –ü—Ä—è–º–∏–π —ñ–º–ø–æ—Ä—Ç –ø–∞—Ä—Å–µ—Ä–∞
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'utils'))
    try:
        from migration_data_parser import MigrationDataParser
    except ImportError:
        MigrationDataParser = None
    UniversalAddressComparator = None

# –î–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º –º—ñ–≥—Ä–∞—Ü—ñ–π–Ω–∏–º —Å–∫—Ä–∏–ø—Ç–æ–º
try:
    from config.database import CONNECTION_STRING
    HAS_CONFIG = True
except ImportError:
    CONNECTION_STRING = None
    HAS_CONFIG = False


class RtgAddrMigrator:
    """–ü–æ–≤–Ω—ñ—Å—Ç—é –ø–µ—Ä–µ—Ä–æ–±–ª–µ–Ω–∏–π –º—ñ–≥—Ä–∞—Ç–æ—Ä –¥–ª—è rtg_addr –∑ —ñ–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—é
    
    –ü—ñ–¥—Ç—Ä–∏–º—É—î –∑–≤–æ—Ä–æ—Ç–Ω—É —Å—É–º—ñ—Å–Ω—ñ—Å—Ç—å –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º migrate.py
    """
    
    def __init__(self, connection_string: str = None):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º—ñ–≥—Ä–∞—Ç–æ—Ä–∞"""
        
        if connection_string:
            self.connection_string = connection_string
        elif HAS_CONFIG and CONNECTION_STRING:
            self.connection_string = CONNECTION_STRING
        else:
            self.connection_string = None
            
        if self.connection_string and HAS_PSYCOPG2:
            try:
                self.connection = psycopg2.connect(self.connection_string)
                self.cursor = self.connection.cursor(cursor_factory=RealDictCursor)
            except Exception as e:
                migration_logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å –¥–æ –ë–î: {e}")
                self.connection = None
                self.cursor = None
        else:
            self.connection = None
            self.cursor = None
            
        self.logger = migration_logger
        
        if MigrationDataParser:
            self.parser = MigrationDataParser()
        else:
            self.parser = None
            migration_logger.error("MigrationDataParser –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
        self.stats = {
            'processed': 0,
            'errors': 0,
            'skipped': 0,
            'created_countries': 0,
            'created_regions': 0,
            'created_districts': 0,
            'created_communities': 0,
            'created_cities': 0,
            'created_city_districts': 0,
            'created_street_types': 0,
            'created_streets': 0,
            'created_buildings': 0,
            'created_premises': 0,
            'duplicates': 0,
            'validated': 0,
            'similar_found': 0,
            'premises_created': 0
        }
        
        # –ö–µ—à—ñ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
        self.cache = {
            'countries': {},
            'regions': {},
            'districts': {},
            'communities': {},
            'cities': {},
            'city_districts': {},
            'street_types': {},
        }
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä–∞ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        try:
            if UniversalAddressComparator:
                self.comparator = UniversalAddressComparator()
            else:
                self.comparator = None
        except:
            self.comparator = None
    
    def setup_source_tracking(self):
        """–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –¥–∞–Ω–∏—Ö"""
        if not self.cursor:
            self.logger.info("–†–µ–∂–∏–º –±–µ–∑ –ë–î: —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—è –¥–∂–µ—Ä–µ–ª–∞ rtg_addr")
            return
        
        try:
            self.cursor.execute("""
                INSERT INTO addrinity.data_sources (name, description) 
                VALUES (%s, %s) 
                ON CONFLICT (name) DO UPDATE SET 
                    description = EXCLUDED.description
            """, ('rtg_addr', '–ú—ñ–≥—Ä–∞—Ü—ñ—è –∑ rtg_addr (—Ñ–∞–π–ª migrations/DATA-TrinitY-3.txt)'))
            self.connection.commit()
            self.logger.info("–î–∂–µ—Ä–µ–ª–æ rtg_addr —É—Å–ø—ñ—à–Ω–æ –∑–∞—Ä–µ—î—Å—Ç—Ä–æ–≤–∞–Ω–æ")
        except Exception as e:
            if self.connection:
                self.connection.rollback()
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞: {e}")
    
    def get_source_id(self):
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è ID –¥–∂–µ—Ä–µ–ª–∞"""
        if not self.cursor:
            return 1  # –§—ñ–∫—Ç–∏–≤–Ω–∏–π ID –¥–ª—è —Ä–µ–∂–∏–º—É –±–µ–∑ –ë–î
            
        try:
            self.cursor.execute("SELECT id FROM addrinity.data_sources WHERE name = 'rtg_addr'")
            result = self.cursor.fetchone()
            return result['id'] if result else None
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è ID –¥–∂–µ—Ä–µ–ª–∞: {e}")
            return None
    
    def normalize_text(self, text: str, obj_type: str = None) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É"""
        if not text:
            return ""
        
        text = str(text).strip()
        text = ' '.join(text.split())
        
        if obj_type == 'street_type' and text:
            type_mapping = {
                '–≤—É–ª.': '–≤—É–ª–∏—Ü—è', '–≤—É–ª': '–≤—É–ª–∏—Ü—è',
                '–ø—Ä–æ—Å–ø.': '–ø—Ä–æ—Å–ø–µ–∫—Ç', '–ø—Ä–æ—Å–ø': '–ø—Ä–æ—Å–ø–µ–∫—Ç',
                '–±—É–ª.': '–±—É–ª—å–≤–∞—Ä', '–±—É–ª': '–±—É–ª—å–≤–∞—Ä',
                '–ø—Ä–æ–≤.': '–ø—Ä–æ–≤—É–ª–æ–∫', '–ø—Ä–æ–≤': '–ø—Ä–æ–≤—É–ª–æ–∫',
                '—à.': '—à–æ—Å–µ', '—à': '—à–æ—Å–µ',
                '—Ç—É–ø.': '—Ç—É–ø–∏–∫', '—Ç—É–ø': '—Ç—É–ø–∏–∫'
            }
            lower_text = text.lower()
            return type_mapping.get(lower_text, text)
        
        return text
    
    def get_or_create_entity(self, table: str, search_field: str, search_value: str, 
                           create_fields: dict, dry_run: bool = False) -> int:
        """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –º–µ—Ç–æ–¥ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—É—Ç–Ω–æ—Å—Ç—ñ –∑ —ñ–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—é"""
        
        cache_key = f"{table}_{search_value}"
        if cache_key in self.cache.get(table, {}):
            self.stats['duplicates'] += 1
            return self.cache[table][cache_key]
        
        if dry_run or not self.cursor:
            # –†–µ–∂–∏–º –±–µ–∑ –ë–î –∞–±–æ DRY RUN
            entity_id = len(self.cache.get(table, {})) + 1
            if table not in self.cache:
                self.cache[table] = {}
            self.cache[table][cache_key] = entity_id
            self.stats[f'created_{table}'] = self.stats.get(f'created_{table}', 0) + 1
            self.logger.debug(f"DRY RUN: —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è {table} - {search_value}")
            return entity_id
        
        try:
            # –ü–æ—à—É–∫ —ñ—Å–Ω—É—é—á–æ–≥–æ
            query = f"SELECT id FROM addrinity.{table} WHERE {search_field} = %s"
            self.cursor.execute(query, (search_value,))
            result = self.cursor.fetchone()
            
            if result:
                entity_id = result['id']
                if table not in self.cache:
                    self.cache[table] = {}
                self.cache[table][cache_key] = entity_id
                self.stats['duplicates'] += 1
                return entity_id
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ
            fields = ', '.join(create_fields.keys())
            placeholders = ', '.join(['%s'] * len(create_fields))
            values = list(create_fields.values())
            
            query = f"""
                INSERT INTO addrinity.{table} ({fields})
                VALUES ({placeholders})
                RETURNING id
            """
            self.cursor.execute(query, values)
            entity_id = self.cursor.fetchone()['id']
            self.connection.commit()
            
            if table not in self.cache:
                self.cache[table] = {}
            self.cache[table][cache_key] = entity_id
            self.stats[f'created_{table}'] = self.stats.get(f'created_{table}', 0) + 1
            
            return entity_id
            
        except Exception as e:
            if self.connection:
                self.connection.rollback()
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è {table}: {e}")
            raise
    
    def process_record(self, record: dict, source_id: int, dry_run: bool = False) -> bool:
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É"""
        
        try:
            if not self.parser:
                self.logger.error("–ü–∞—Ä—Å–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")
                return False
                
            # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞–ø–∏—Å—É
            normalized = self.parser.normalize_record(record)
            
            # –ë–∞–∑–æ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
            if not normalized.get('path') or not normalized.get('city'):
                self.logger.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–∞–ø–∏—Å {normalized.get('id', 'unknown')}: –Ω–µ–º–∞—î path –∞–±–æ –º—ñ—Å—Ç–∞")
                self.stats['skipped'] += 1
                return False
            
            # –ü–∞—Ä—Å–∏–Ω–≥ —ñ—î—Ä–∞—Ä—Ö—ñ—ó
            hierarchy = self.parser.parse_path_hierarchy(normalized['path'])
            
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ—î—Ä–∞—Ä—Ö—ñ—ó –∞–¥–º—ñ–Ω–æ–¥–∏–Ω–∏—Ü—å
            try:
                # –ö—Ä–∞—ó–Ω–∞
                country_id = self.get_or_create_entity(
                    'countries', 'iso_code', 'UA',
                    {
                        'iso_code': 'UA',
                        'name_uk': '–£–∫—Ä–∞—ó–Ω–∞',
                        'rtg_country_id': hierarchy.get('country')
                    },
                    dry_run
                )
                
                # –†–µ–≥—ñ–æ–Ω
                region_id = self.get_or_create_entity(
                    'regions', 'name_uk', normalized['region'],
                    {
                        'country_id': country_id,
                        'name_uk': normalized['region'],
                        'rtg_region_id': hierarchy.get('region')
                    },
                    dry_run
                )
                
                # –†–∞–π–æ–Ω
                district_id = self.get_or_create_entity(
                    'districts', 'name_uk', normalized['district'],
                    {
                        'region_id': region_id,
                        'name_uk': normalized['district'],
                        'rtg_district_id': hierarchy.get('district')
                    },
                    dry_run
                )
                
                # –ì—Ä–æ–º–∞–¥–∞  
                community_id = self.get_or_create_entity(
                    'communities', 'name_uk', normalized['community'],
                    {
                        'district_id': district_id,
                        'name_uk': normalized['community'],
                        'type': '–º—ñ—Å—å–∫–∞' if '–º—ñ—Å—å–∫–∞' in normalized['community'].lower() else '—Å—ñ–ª—å—Å—å–∫–∞',
                        'rtg_community_id': hierarchy.get('community')
                    },
                    dry_run
                )
                
                # –ú—ñ—Å—Ç–æ
                city_id = self.get_or_create_entity(
                    'cities', 'name_uk', normalized['city'],
                    {
                        'community_id': community_id,
                        'name_uk': normalized['city'],
                        'type': normalized.get('city_type', '–º.'),
                        'rtg_city_id': hierarchy.get('city')
                    },
                    dry_run
                )
                
                # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤'—è–∑–∫—É –∑ –¥–∂–µ—Ä–µ–ª–æ–º
                self.save_object_source('city', city_id, source_id, normalized, dry_run)
                
                self.stats['processed'] += 1
                self.stats['validated'] += 1
                return True
                
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ—î—Ä–∞—Ä—Ö—ñ—ó –¥–ª—è –∑–∞–ø–∏—Å—É {normalized.get('id')}: {e}")
                self.stats['errors'] += 1
                return False
                
        except Exception as e:
            self.stats['errors'] += 1
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Å—É {record.get('id', 'unknown')}: {e}")
            return False
    
    def save_object_source(self, object_type: str, object_id: int, source_id: int, 
                          original_data: dict, dry_run: bool = False) -> bool:
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤'—è–∑–∫—É –æ–±'—î–∫—Ç–∞ –∑ –¥–∂–µ—Ä–µ–ª–æ–º"""
        
        if dry_run or not self.cursor:
            self.logger.debug(f"{'DRY RUN: ' if dry_run else ''}–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –¥–ª—è {object_type}:{object_id}")
            return True
        
        try:
            self.cursor.execute("""
                INSERT INTO addrinity.object_sources 
                (object_type, object_id, source_id, original_data)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (object_type, object_id, source_id) DO UPDATE SET
                    original_data = EXCLUDED.original_data
            """, (object_type, object_id, source_id, json.dumps(original_data, ensure_ascii=False)))
            
            self.connection.commit()
            return True
            
        except Exception as e:
            if self.connection:
                self.connection.rollback()
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –¥–ª—è {object_type}:{object_id}: {e}")
            return False
    
    def migrate(self, dry_run: bool = False, batch_size: int = 1000) -> dict:
        """–ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –º—ñ–≥—Ä–∞—Ü—ñ—ó –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É"""
        
        self.logger.info(f"{'DRY RUN: ' if dry_run else ''}–ü–æ—á–∞—Ç–æ–∫ –º—ñ–≥—Ä–∞—Ü—ñ—ó rtg_addr")
        
        if not self.parser:
            self.logger.error("–ü–∞—Ä—Å–µ—Ä –º—ñ–≥—Ä–∞—Ü—ñ–π–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")
            return self.stats
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞
        self.setup_source_tracking()
        source_id = self.get_source_id()
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ —Ñ–∞–π–ª—É
        try:
            records = self.parser.parse_rtg_addr_section()
            total_records = len(records)
            self.logger.info(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_records} –∑–∞–ø–∏—Å—ñ–≤ –∑ —Ñ–∞–π–ª—É –º—ñ–≥—Ä–∞—Ü—ñ—ó")
            
            if dry_run:
                records = records[:min(100, total_records)]
                self.logger.info(f"DRY RUN: –û–±—Ä–æ–±–ª—è—î–º–æ –ª–∏—à–µ {len(records)} –∑–∞–ø–∏—Å—ñ–≤")
            
        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
            return self.stats
        
        # –û–±—Ä–æ–±–∫–∞ –∑–∞–ø–∏—Å—ñ–≤
        progress_desc = f"{'DRY RUN: ' if dry_run else ''}–ú—ñ–≥—Ä–∞—Ü—ñ—è rtg_addr"
        
        if HAS_TQDM:
            progress_bar = tqdm(total=len(records), desc=progress_desc)
        
        for i, record in enumerate(records):
            self.process_record(record, source_id, dry_run)
            
            if HAS_TQDM:
                progress_bar.update(1)
            elif i % 50 == 0:
                self.logger.info(f"–û–±—Ä–æ–±–ª–µ–Ω–æ {i}/{len(records)} –∑–∞–ø–∏—Å—ñ–≤")
        
        if HAS_TQDM:
            progress_bar.close()
        
        # –ó–≤—ñ—Ç –ø—Ä–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        self._print_migration_summary(dry_run)
        return self.stats
    
    def _print_migration_summary(self, dry_run: bool = False):
        """–î—Ä—É–∫ –ø—ñ–¥—Å—É–º–∫–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É"""
        prefix = "DRY RUN: " if dry_run else ""
        
        self.logger.info("=" * 60)
        self.logger.info(f"{prefix}–ü–Ü–î–°–£–ú–û–ö –ú–Ü–ì–†–ê–¶–Ü–á RTG_ADDR")
        self.logger.info("=" * 60)
        
        self.logger.info(f"–û–±—Ä–æ–±–ª–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤: {self.stats['processed']}")
        self.logger.info(f"–ü–æ–º–∏–ª–∫–∏: {self.stats['errors']}")
        self.logger.info(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: {self.stats['skipped']}")
        self.logger.info(f"–î—É–±–ª—ñ–∫–∞—Ç–∏: {self.stats['duplicates']}")
        
        creation_stats = {k.replace('created_', ''): v for k, v in self.stats.items() if k.startswith('created_') and v > 0}
        if creation_stats:
            self.logger.info("\n–°—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏—Ö –æ–±'—î–∫—Ç—ñ–≤:")
            for key, value in creation_stats.items():
                self.logger.info(f"  {key}: {value}")


# –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏
def create_migration_instructions():
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π –¥–ª—è –∑–∞–ø—É—Å–∫—É –º—ñ–≥—Ä–∞—Ü—ñ—ó"""
    instructions = '''# –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –ø–æ –∑–∞–ø—É—Å–∫—É —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–æ–≤–∞–Ω–æ—ó –º—ñ–≥—Ä–∞—Ü—ñ—ó RTG_ADDR

## –û–≥–ª—è–¥ –∑–º—ñ–Ω
–ü–æ–≤–Ω—ñ—Å—Ç—é —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–æ–≤–∞–Ω–∏–π –º—ñ–≥—Ä–∞—Ç–æ—Ä –∑ –Ω–∞—Å—Ç—É–ø–Ω–∏–º–∏ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏:
- ‚úÖ –Ü–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ñ INSERT ... ON CONFLICT –æ–ø–µ—Ä–∞—Ü—ñ—ó
- ‚úÖ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–∞–∑–≤ —Ç–∞ —Ç–∏–ø—ñ–≤
- ‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É JSONB
- ‚úÖ –û–±—Ä–æ–±–∫–∞ edge cases (NULL, –ø—É—Å—Ç—ñ –∑–Ω–∞—á–µ–Ω–Ω—è)
- ‚úÖ –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- ‚úÖ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ DRY RUN —Ä–µ–∂–∏–º—É
- ‚úÖ –ß–∏—Ç–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ —Ñ–∞–π–ª—É migrations/DATA-TrinitY-3.txt

## –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
```bash
pip install psycopg2-binary tqdm
```

## –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω–∏–π —Å–∫—Ä–∏–ø—Ç migrate.py
```bash
# –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø—É—Å–∫
python migrate.py --tables rtg_addr --dry-run --batch-size 50

# –ü–æ–≤–Ω–∞ –º—ñ–≥—Ä–∞—Ü—ñ—è
python migrate.py --tables rtg_addr --batch-size 1000
```

## –ü—Ä—è–º–∏–π –∑–∞–ø—É—Å–∫
```python
from src.migrators.rtg_addr import RtgAddrMigrator
from config.database import CONNECTION_STRING

# –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø—É—Å–∫
migrator = RtgAddrMigrator(CONNECTION_STRING)
migrator.migrate(dry_run=True, batch_size=50)

# –ü–æ–≤–Ω–∞ –º—ñ–≥—Ä–∞—Ü—ñ—è
migrator.migrate(dry_run=False, batch_size=1000)
```

## –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó
- –ß–∏—Ç–∞—î –¥–∞–Ω—ñ –∑ —Ñ–∞–π–ª—É migrations/DATA-TrinitY-3.txt
- –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ä–æ–±–æ—Ç—É –±–µ–∑ –ë–î (DRY RUN —Ä–µ–∂–∏–º)
- –ö–µ—à—É–≤–∞–Ω–Ω—è –¥–ª—è –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ –ë–î
- –ü–æ–≤–Ω–∞ –∑–≤–æ—Ä–æ—Ç–Ω–∞ —Å—É–º—ñ—Å–Ω—ñ—Å—Ç—å –∑ —ñ—Å–Ω—É—é—á–∏–º –∫–æ–¥–æ–º

## –õ–æ–≥–∏
–õ–æ–≥–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ logs/migration.log –∑ –¥–µ—Ç–∞–ª—å–Ω–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ—é.
'''
    
    try:
        with open('/home/runner/work/ADDR3_new3/ADDR3_new3/MIGRATION_RTG_ADDR_INSTRUCTIONS.md', 'w', encoding='utf-8') as f:
            f.write(instructions)
        return True
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π: {e}")
        return False


if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø—É—Å–∫
    print("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–æ–≤–∞–Ω–æ–≥–æ RTG_ADDR –º—ñ–≥—Ä–∞—Ç–æ—Ä–∞")
    
    try:
        migrator = RtgAddrMigrator()
        migrator.migrate(dry_run=True, batch_size=10)
        
        print("\nüìã –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π...")
        if create_migration_instructions():
            print("‚úÖ –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó —Å—Ç–≤–æ—Ä–µ–Ω–æ –≤ MIGRATION_RTG_ADDR_INSTRUCTIONS.md")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()